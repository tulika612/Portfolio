{
    "experiences": [
        {
            "title": "Machine Learning Engineer",
            "subtitle": "Salesforce",
            "workType": "Full-time",
            "workDescription": [
                "Developed xLAMFlow in Swift, an iOS productivity assistant powered by quantized xLAM-2, supporting single-step, multi-turn, and multi-step agentic scenarios demonstrating on-device AI, privacy-preserving inference and end-to-end user experience integration.",
                "Advanced model training pipelines by preprocessing datasets (AgentBank, ToolACE, BFCL) and fine-tuning Qwen-1B/3B/8B and Llama3-8B, released as xLAM-2, then quantized to GGUF format for edge deployment. ",
                "Developed a feedback-driven pipeline with external annotators to assess and refine agentic data, updating 25.6% of samples for improved fine-tuning robustness."
                "Designed and open-sourced MobileAIBench, a cross-platform iOS/Android benchmarking framework to evaluate on-device LLM/LMM performance, leveraging llama.cpp quantization (4-bit, 8-bit, 16-bit) for efficiency. ",
                "Optimized multimodal inference by quantizing and deploying internal xGen-MM models on-device, enabling low-latency multimodal reasoning directly on mobile hardware. "
            ],
            "dateText": "01/2024 – Present"
        },
        {
            "title": "Founding Engineer",
            "subtitle": "Lamini AI",
            "workType": "Full-time",
            "workDescription": [
                "Moved existing system to serverless using Azure functions and automated the process using Terraform on GitHub actions, extending support for up to 10,000 users",
                "Enabled training and inference of LLM with LORA peft optimization which resulted in 10 times faster switch time",
                "Integrated Multi-GPU inference using deepspeed, allowing running inference on bigger models, i.e. 13b->70b parameters",
                "Orchestrated a Machine learning pipeline for fine-tuning LLM models using Slurm to optimize GPU usage"
            ],
            "dateText": "02/2023 – 12/2023"
        },
        {
            "title": "Intern-Member of Technical Staff",
            "subtitle": "VMware Inc.",
            "workType": "Full-time",
            "workDescription": [
                "Analyzed Bitfusion performance for different ML benchmark usage scenarios, architecture, and AI frameworks",
                "Automated MLPerf Inference benchmark on NVIDIA GPU and integrated it with existing CI/CD pipeline",
                "Designed software to parse output for different benchmarks and compared their performance on wavefront"
            ],
            "dateText": "06/2022 – 09/2022"
        },
        {
            "title": "Software Engineer",
            "subtitle": "Earthsense India",
            "workType": "Full-time",
            "workDescription": [
                "Migrated existing system from AWS S3 to Microsoft Azure storage and integrated it with visual plot split code",
                "Optimized supervised visual plot split code by removing outliers, which resulted in a 6.06% increase in accuracy",
                "Trained deep neural model for calculating the width of crops to attain an R squared value of 0.752 on manual measurement data"
            ],
            "dateText": "05/2021 – 08/2021"
        },
        {
            "title": "Winter Intern",
            "subtitle": "Indian Institute of Space Science and Technology ",
            "workType": "Internship",
            "workDescription": [
                "Deployed an Automated Attendance System using facial recognition, and results were stored in the SQL database",
                "Trained a deep neural model based on VGGFace resnet50 architecture to achieve a testing accuracy of 82.71%"
            ],
            "dateText": "12/2019 – 01/2020"
        }
    ]
}
